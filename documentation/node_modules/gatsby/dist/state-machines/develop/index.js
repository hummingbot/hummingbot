"use strict";

exports.__esModule = true;
exports.developMachine = void 0;

var _xstate = require("xstate");

var _actions = require("./actions");

var _services = require("./services");

const RECOMPILE_PANIC_LIMIT = 6;
/**
 * This is the top-level state machine for the `gatsby develop` command
 */

const developConfig = {
  id: `build`,
  initial: `initializing`,
  // These are mutation events, sent to this machine by the mutation listener
  // in `services/listen-for-mutations.ts`
  on: {
    // These are deferred node mutations, mainly `createNode`
    ADD_NODE_MUTATION: {
      actions: `addNodeMutation`
    },
    // Sent when webpack or chokidar sees a changed file
    SOURCE_FILE_CHANGED: {
      actions: `markSourceFilesDirty`
    },
    // These are calls to the refresh endpoint. Also used by Gatsby Preview.
    // Saves the webhook body from the event into context, then reloads data
    WEBHOOK_RECEIVED: {
      target: `reloadingData`,
      actions: `assignWebhookBody`
    }
  },
  states: {
    // Here we handle the initial bootstrap
    initializing: {
      on: {
        // Ignore mutation events because we'll be running everything anyway
        ADD_NODE_MUTATION: undefined,
        SOURCE_FILE_CHANGED: undefined,
        WEBHOOK_RECEIVED: undefined
      },
      invoke: {
        id: `initialize`,
        src: `initialize`,
        onDone: {
          target: `initializingData`,
          actions: [`assignStoreAndWorkerPool`, `spawnMutationListener`]
        },
        onError: {
          actions: `panic`
        }
      }
    },
    // Sourcing nodes, customising and inferring schema, then running createPages
    initializingData: {
      on: {
        // We need to run mutations immediately when in this state
        ADD_NODE_MUTATION: {
          actions: `callApi`
        }
      },
      invoke: {
        id: `initialize-data`,
        src: `initializeData`,
        data: ({
          parentSpan,
          store,
          webhookBody
        }) => {
          return {
            parentSpan,
            store,
            webhookBody,
            deferNodeMutation: true
          };
        },
        onDone: {
          actions: [`assignServiceResult`, `clearWebhookBody`, `finishParentSpan`],
          target: `runningPostBootstrap`
        },
        onError: {
          actions: `logError`,
          target: `waiting`
        }
      }
    },
    runningPostBootstrap: {
      invoke: {
        id: `post-bootstrap`,
        src: `postBootstrap`,
        onDone: `runningQueries`
      }
    },
    // Running page and static queries and generating the SSRed HTML and page data
    runningQueries: {
      on: {
        SOURCE_FILE_CHANGED: {
          actions: [(0, _xstate.forwardTo)(`run-queries`), `markSourceFilesDirty`]
        },
        ADD_NODE_MUTATION: {
          actions: [`markNodesDirty`, `callApi`]
        }
      },
      invoke: {
        id: `run-queries`,
        src: `runQueries`,
        // This is all the data that we're sending to the child machine
        data: ({
          program,
          store,
          parentSpan,
          gatsbyNodeGraphQLFunction,
          graphqlRunner,
          websocketManager
        }) => {
          return {
            program,
            store,
            parentSpan,
            gatsbyNodeGraphQLFunction,
            graphqlRunner,
            websocketManager
          };
        },
        onDone: [{
          // If we're at the recompile limit and nodes were mutated again then panic
          target: `waiting`,
          actions: `panicBecauseOfInfiniteLoop`,
          cond: ({
            nodesMutatedDuringQueryRun = false,
            nodesMutatedDuringQueryRunRecompileCount = 0
          }) => nodesMutatedDuringQueryRun && nodesMutatedDuringQueryRunRecompileCount >= RECOMPILE_PANIC_LIMIT
        }, {
          // Nodes were mutated while querying, so we need to re-run everything
          target: `recreatingPages`,
          cond: ({
            nodesMutatedDuringQueryRun
          }) => !!nodesMutatedDuringQueryRun,
          actions: [`markNodesClean`, `incrementRecompileCount`]
        }, {
          // If we have no compiler (i.e. it's first run), then spin up the
          // webpack and socket.io servers
          target: `startingDevServers`,
          actions: `setQueryRunningFinished`,
          cond: ({
            compiler
          }) => !compiler
        }, {
          // If source files have changed, then recompile the JS bundle
          target: `recompiling`,
          cond: ({
            sourceFilesDirty
          }) => !!sourceFilesDirty
        }, {
          // ...otherwise just wait.
          target: `waiting`
        }],
        onError: {
          actions: `logError`,
          target: `waiting`
        }
      }
    },
    // Recompile the JS bundle
    recompiling: {
      invoke: {
        src: `recompile`,
        onDone: {
          actions: `markSourceFilesClean`,
          target: `waiting`
        },
        onError: {
          actions: `logError`,
          target: `waiting`
        }
      }
    },
    // Spin up webpack and socket.io
    startingDevServers: {
      invoke: {
        src: `startWebpackServer`,
        onDone: {
          target: `waiting`,
          actions: [`assignServers`, `spawnWebpackListener`, `markSourceFilesClean`]
        },
        onError: {
          actions: `panic`,
          target: `waiting`
        }
      }
    },
    // Idle, waiting for events that make us rebuild
    waiting: {
      entry: [`saveDbState`, `resetRecompileCount`],
      on: {
        // Forward these events to the child machine, so it can handle batching
        ADD_NODE_MUTATION: {
          actions: (0, _xstate.forwardTo)(`waiting`)
        },
        SOURCE_FILE_CHANGED: {
          actions: [(0, _xstate.forwardTo)(`waiting`), `markSourceFilesDirty`]
        },
        // This event is sent from the child
        EXTRACT_QUERIES_NOW: {
          target: `runningQueries`
        }
      },
      invoke: {
        id: `waiting`,
        src: `waitForMutations`,
        // Send existing queued mutations to the child machine, which will execute them
        data: ({
          store,
          nodeMutationBatch = []
        }) => {
          return {
            store,
            nodeMutationBatch,
            runningBatch: []
          };
        },
        // "done" means we need to rebuild
        onDone: {
          actions: `assignServiceResult`,
          target: `recreatingPages`
        },
        onError: {
          actions: `panic`
        }
      }
    },
    // Almost the same as initializing data, but skips various first-run stuff
    reloadingData: {
      on: {
        // We need to run mutations immediately when in this state
        ADD_NODE_MUTATION: {
          actions: `callApi`
        },
        // Ignore, because we're about to extract them anyway
        SOURCE_FILE_CHANGED: undefined
      },
      invoke: {
        src: `reloadData`,
        data: ({
          parentSpan,
          store,
          webhookBody
        }) => {
          return {
            parentSpan,
            store,
            webhookBody,
            refresh: true,
            deferNodeMutation: true
          };
        },
        onDone: {
          actions: [`assignServiceResult`, `clearWebhookBody`, `finishParentSpan`],
          target: `runningQueries`
        },
        onError: {
          actions: `logError`,
          target: `waiting`
        }
      }
    },
    // Rebuild pages if a node has been mutated outside of sourceNodes
    recreatingPages: {
      on: {
        // We need to run mutations immediately when in this state
        ADD_NODE_MUTATION: {
          actions: `callApi`
        }
      },
      invoke: {
        id: `recreate-pages`,
        src: `recreatePages`,
        data: ({
          parentSpan,
          store
        }) => {
          return {
            parentSpan,
            store,
            deferNodeMutation: true
          };
        },
        onDone: {
          actions: `assignServiceResult`,
          target: `runningQueries`
        },
        onError: {
          actions: `logError`,
          target: `waiting`
        }
      }
    }
  }
};
const developMachine = (0, _xstate.Machine)(developConfig, {
  services: _services.developServices,
  actions: _actions.buildActions
});
exports.developMachine = developMachine;
//# sourceMappingURL=index.js.map